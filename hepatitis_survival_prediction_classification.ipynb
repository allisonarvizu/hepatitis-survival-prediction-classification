{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e90f25-9cb9-4283-b456-d6c53e24a884",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "The training and testing datasets were loaded from local CSV files using pandas.\n",
    "File paths were constructed dynamically to ensure portability across different\n",
    "environments. An initial inspection of the training data was performed to verify\n",
    "successful loading and confirm the structure of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37b147fc-b124-4ff5-add0-8f839f482b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train path: /Users/allisonarvizu/Downloads/Hepatitis-Train.csv\n",
      "Test path: /Users/allisonarvizu/Downloads/Hepatitis-Test.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Steroid</th>\n",
       "      <th>Antivirals</th>\n",
       "      <th>Fatigue</th>\n",
       "      <th>Malaise</th>\n",
       "      <th>Anorexia</th>\n",
       "      <th>Liver Big</th>\n",
       "      <th>Liver Firm</th>\n",
       "      <th>Spleen Palpable</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Varices</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>ALK Phosphate</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>PROTIME</th>\n",
       "      <th>Histology</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85</td>\n",
       "      <td>18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.16</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Male</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.9</td>\n",
       "      <td>135</td>\n",
       "      <td>42</td>\n",
       "      <td>3.5</td>\n",
       "      <td>62.16</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>Male</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.7</td>\n",
       "      <td>96</td>\n",
       "      <td>32</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.16</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.7</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>Male</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104</td>\n",
       "      <td>200</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.16</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age     Sex Steroid Antivirals Fatigue Malaise Anorexia Liver Big  \\\n",
       "0   30  Female      no        yes     yes     yes      yes        no   \n",
       "1   50    Male      no        yes      no     yes      yes        no   \n",
       "2   78    Male     yes        yes      no     yes      yes       yes   \n",
       "3   31    Male      no         no     yes     yes      yes       yes   \n",
       "4   34    Male     yes        yes     yes     yes      yes       yes   \n",
       "\n",
       "  Liver Firm Spleen Palpable Spiders Ascites Varices  Bilirubin  \\\n",
       "0        yes             yes     yes     yes     yes        1.0   \n",
       "1        yes             yes     yes     yes     yes        0.9   \n",
       "2        yes             yes     yes     yes     yes        0.7   \n",
       "3        yes             yes     yes     yes     yes        0.7   \n",
       "4        yes             yes     yes     yes     yes        1.0   \n",
       "\n",
       "   ALK Phosphate  SGOT  Albumin  PROTIME Histology  TARGET  \n",
       "0             85    18      4.0    62.16        no       2  \n",
       "1            135    42      3.5    62.16        no       2  \n",
       "2             96    32      4.0    62.16        no       2  \n",
       "3             46    52      4.0    80.00        no       2  \n",
       "4            104   200      4.0    62.16        no       2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Automatically get your username + home folder\n",
    "home = os.path.expanduser(\"~\")\n",
    "\n",
    "train_path = os.path.join(home, \"Downloads\", \"Hepatitis-Train.csv\")\n",
    "test_path  = os.path.join(home, \"Downloads\", \"Hepatitis-Test.csv\")\n",
    "\n",
    "print(\"Train path:\", train_path)\n",
    "print(\"Test path:\", test_path)\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1818f455-ce9b-4075-b696-64315bc60ea6",
   "metadata": {},
   "source": [
    "## Feature Types and Preprocessing Pipeline\n",
    "\n",
    "The dataset contains a mix of numerical and categorical features. Numerical and\n",
    "categorical columns were identified programmatically to ensure flexibility and\n",
    "reduce manual specification.\n",
    "\n",
    "A preprocessing pipeline was constructed to standardize numerical features and\n",
    "apply one-hot encoding to categorical variables. This approach allows consistent\n",
    "and reusable preprocessing across all classification models while preventing\n",
    "data leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67e4d11f-7140-451b-a32f-ad6db3291c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['Age', 'Bilirubin', 'ALK Phosphate', 'SGOT', 'Albumin', 'PROTIME', 'TARGET']\n",
      "Categorical columns: ['Sex', 'Steroid', 'Antivirals', 'Fatigue', 'Malaise', 'Anorexia', 'Liver Big', 'Liver Firm', 'Spleen Palpable', 'Spiders', 'Ascites', 'Varices', 'Histology']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = train_df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbed1dee-84ad-4f81-9477-32a621a291b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"YOUR_COLUMN_NAME\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d351e0cb-794a-491e-bd41-3e827b8dbad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor created.\n",
      "Numeric columns: ['Age', 'Bilirubin', 'ALK Phosphate', 'SGOT', 'Albumin', 'PROTIME', 'TARGET']\n",
      "Categorical columns: ['Sex', 'Steroid', 'Antivirals', 'Fatigue', 'Malaise', 'Anorexia', 'Liver Big', 'Liver Firm', 'Spleen Palpable', 'Spiders', 'Ascites', 'Varices', 'Histology']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = train_df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "numeric_cols = [c for c in numeric_cols if c != target_col]\n",
    "categorical_cols = [c for c in categorical_cols if c != target_col]\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Preprocessor created.\")\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc5cdf-d781-4199-aaef-489baf50b335",
   "metadata": {},
   "source": [
    "## Target Variable and Modeling Pipeline Setup\n",
    "\n",
    "The target variable was identified from the dataset and separated from the feature\n",
    "set for both the training and testing data. Features were divided into numerical and\n",
    "categorical types to support appropriate preprocessing.\n",
    "\n",
    "A unified preprocessing pipeline was constructed using a column transformer. Numerical\n",
    "features were standardized, while categorical features were one-hot encoded. This\n",
    "pipeline is reused across all classification models to ensure consistent preprocessing\n",
    "and fair model comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed8adead-6c49-4b8a-b777-bff92ce734a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using target column: TARGET\n",
      "Numeric columns: ['Age', 'Bilirubin', 'ALK Phosphate', 'SGOT', 'Albumin', 'PROTIME']\n",
      "Categorical columns: ['Sex', 'Steroid', 'Antivirals', 'Fatigue', 'Malaise', 'Anorexia', 'Liver Big', 'Liver Firm', 'Spleen Palpable', 'Spiders', 'Ascites', 'Varices', 'Histology']\n",
      "\n",
      "=== LinearSVC (default) ===\n",
      "Accuracy : 0.7273\n",
      "Precision: 0.7143\n",
      "Recall   : 0.8333\n",
      "F1 Score : 0.7692\n",
      "\n",
      "=== DecisionTree (default) ===\n",
      "Accuracy : 0.8182\n",
      "Precision: 0.8333\n",
      "Recall   : 0.8333\n",
      "F1 Score : 0.8333\n",
      "\n",
      "=== RandomForest (default) ===\n",
      "Accuracy : 0.8182\n",
      "Precision: 0.8333\n",
      "Recall   : 0.8333\n",
      "F1 Score : 0.8333\n",
      "\n",
      "=== KNN (default) ===\n",
      "Accuracy : 0.8182\n",
      "Precision: 0.8333\n",
      "Recall   : 0.8333\n",
      "F1 Score : 0.8333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "target_col = train_df.columns[-1]\n",
    "print(\"Using target column:\", target_col)\n",
    "\n",
    "X_train = train_df.drop(columns=[target_col])\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "X_test = test_df.drop(columns=[target_col])\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def evaluate_model(name, model):\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocess\", preprocessor),\n",
    "            (\"clf\", model),\n",
    "        ]\n",
    "    )\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1\": f1,\n",
    "        \"Pipeline\": pipe,\n",
    "    }\n",
    "\n",
    "results = []\n",
    "results.append(evaluate_model(\"LinearSVC (default)\", LinearSVC()))\n",
    "results.append(evaluate_model(\"DecisionTree (default)\", DecisionTreeClassifier()))\n",
    "results.append(evaluate_model(\"RandomForest (default)\", RandomForestClassifier()))\n",
    "results.append(evaluate_model(\"KNN (default)\", KNeighborsClassifier()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164799d2-c948-46ec-bf29-a341843bc61b",
   "metadata": {},
   "source": [
    "## Random Forest Hyperparameter Tuning\n",
    "\n",
    "To improve model performance, hyperparameter tuning was performed on the Random Forest\n",
    "classifier using randomized search with cross-validation. Several key hyperparameters,\n",
    "including the number of trees, maximum tree depth, minimum samples for splits and leaves,\n",
    "and feature selection strategy, were explored.\n",
    "\n",
    "Randomized search was chosen to efficiently sample the hyperparameter space while\n",
    "balancing computational cost. The best-performing model was selected based on F1 score\n",
    "and used for subsequent evaluation on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d04dde8b-bf9c-4346-897d-aa777881da79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RandomizedSearchCV...\n",
      "\n",
      "Best Parameters Found:\n",
      "{'clf__max_depth': 2, 'clf__max_features': None, 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 18, 'clf__n_estimators': 185}\n",
      "\n",
      "=== RandomForest (Tuned) ===\n",
      "Accuracy : 0.4545\n",
      "Precision: 0.5000\n",
      "Recall   : 0.1667\n",
      "F1 Score : 0.2500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "rf_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"clf\", RandomForestClassifier(random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    \"clf__n_estimators\": randint(50, 300),\n",
    "    \"clf__max_depth\": randint(2, 20),\n",
    "    \"clf__min_samples_split\": randint(2, 20),\n",
    "    \"clf__min_samples_leaf\": randint(1, 10),\n",
    "    \"clf__max_features\": [\"sqrt\", \"log2\", None],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf_pipe,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,             \n",
    "    cv=5,                  \n",
    "    scoring='f1',         \n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Running RandomizedSearchCV...\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Parameters Found:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "best_rf = random_search.best_estimator_\n",
    "y_pred_tuned = best_rf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_tuned)\n",
    "prec = precision_score(y_test, y_pred_tuned, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred_tuned, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred_tuned, zero_division=0)\n",
    "\n",
    "print(\"\\n=== RandomForest (Tuned) ===\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"RandomForest (Tuned)\",\n",
    "    \"Accuracy\": acc,\n",
    "    \"Precision\": prec,\n",
    "    \"Recall\": rec,\n",
    "    \"F1\": f1,\n",
    "    \"Pipeline\": best_rf\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2db22d-9067-4b50-a392-e1f86eb21f2b",
   "metadata": {},
   "source": [
    "## Feature Importance from Tuned Random Forest\n",
    "\n",
    "To better understand model behavior, feature importance scores from the tuned Random\n",
    "Forest classifier were examined. These scores indicate the relative contribution of\n",
    "each feature to the model’s predictions.\n",
    "\n",
    "The top-ranked features provide insight into which clinical variables are most strongly\n",
    "associated with hepatitis survival outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce7717e5-9d53-40d2-8128-8d7254e68598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Most Important Features (Tuned RF):\n",
      "        Feature  Importance\n",
      "4       Albumin    0.469603\n",
      "1     Bilirubin    0.184992\n",
      "5       PROTIME    0.140076\n",
      "29  Varices_yes    0.065931\n",
      "28   Varices_no    0.035061\n"
     ]
    }
   ],
   "source": [
    "rf_clf = results[-1][\"Pipeline\"].named_steps[\"clf\"]\n",
    "\n",
    "ohe = results[-1][\"Pipeline\"].named_steps[\"preprocess\"].named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "cat_feature_names = ohe.get_feature_names_out(results[-1][\"Pipeline\"].named_steps[\"preprocess\"].transformers_[1][2])\n",
    "\n",
    "all_feature_names = np.concatenate([numeric_cols, cat_feature_names])\n",
    "\n",
    "importances = rf_clf.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    \"Feature\": all_feature_names,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "top5 = feature_importance_df.head(5)\n",
    "print(\"\\nTop 5 Most Important Features (Tuned RF):\")\n",
    "print(top5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26044067-dee9-4454-9d91-dddf6a01417b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Stacking (LinearSVC + DT + RF + KNN → MLP) ===\n",
      "Accuracy : 0.6364\n",
      "Precision: 1.0000\n",
      "Recall   : 0.3333\n",
      "F1 Score : 0.5000\n",
      "\n",
      "=== FINAL SUMMARY TABLE ===\n",
      "                 Model  Accuracy  Precision   Recall       F1\n",
      "   LinearSVC (default)  0.727273   0.714286 0.833333 0.769231\n",
      "DecisionTree (default)  0.818182   0.833333 0.833333 0.833333\n",
      "RandomForest (default)  0.818182   0.833333 0.833333 0.833333\n",
      "         KNN (default)  0.818182   0.833333 0.833333 0.833333\n",
      "  RandomForest (Tuned)  0.454545   0.500000 0.166667 0.250000\n",
      "   Stacking (MLP meta)  0.636364   1.000000 0.333333 0.500000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "base_estimators = [\n",
    "    (\"svc\", LinearSVC()),\n",
    "    (\"dt\", DecisionTreeClassifier(random_state=42)),\n",
    "    (\"rf\", RandomForestClassifier(random_state=42)),\n",
    "    (\"knn\", KNeighborsClassifier())\n",
    "]\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_estimators,\n",
    "    final_estimator=MLPClassifier(random_state=42, max_iter=1000),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"clf\", stacking_clf),\n",
    "    ]\n",
    ")\n",
    "\n",
    "stacking_pipe.fit(X_train, y_train)\n",
    "y_pred_stack = stacking_pipe.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_stack)\n",
    "prec = precision_score(y_test, y_pred_stack, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred_stack, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred_stack, zero_division=0)\n",
    "\n",
    "print(\"\\n=== Stacking (LinearSVC + DT + RF + KNN → MLP) ===\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Stacking (MLP meta)\",\n",
    "    \"Accuracy\": acc,\n",
    "    \"Precision\": prec,\n",
    "    \"Recall\": rec,\n",
    "    \"F1\": f1,\n",
    "    \"Pipeline\": stacking_pipe\n",
    "})\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "summary_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"Model\": r[\"Model\"],\n",
    "            \"Accuracy\": r[\"Accuracy\"],\n",
    "            \"Precision\": r[\"Precision\"],\n",
    "            \"Recall\": r[\"Recall\"],\n",
    "            \"F1\": r[\"F1\"],\n",
    "        }\n",
    "        for r in results\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\n=== FINAL SUMMARY TABLE ===\")\n",
    "print(summary_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726c157-662e-49b7-9639-289ab9a0375c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3] *",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
